%% CS 532 Final Project -- Rita Roloff, Justin Essert, Aaron Levin
close all; clear all;
%% Load data
train_images = loadMNISTImages('MNIST/train-images-idx3-ubyte');
train_labels = loadMNISTLabels('MNIST/train-labels-idx1-ubyte');

test_images = loadMNISTImages('MNIST/t10k-images-idx3-ubyte');
test_labels = loadMNISTLabels('MNIST/t10k-labels-idx1-ubyte');

% Training and testing images are known to be 28x28 from the dataset
% specifications, but, the manner in which we are loading them puts them
% into a neural-network-friendly 2D format of: 
%   784x60000 (training images)
%   784x10000 (testing images)
%   60000x1   (training labels)
%   10000x1   (testing labels)

%% Setup hyperparameters





num_hidden = 784;   % number of hidden 
act_func = 2;       % activation function
alpha = 0.01;       % step size
epsilon = .0001;    % convergence factor
batch = 1000;        % batch size
max_epoch = 0;      % number of training iterations to run

%% Train Network
[ w, v, t ] = train_network(train_images, train_images, num_hidden, act_func, alpha, epsilon, batch, max_epoch );

if(t==max_epoch)
    disp('Did not converge, stopped after ' num2int(t), ' epochs');
els
    disp('Did not converge, stopped after ' num2int(t), ' epochs');

%% Test Autoencoder

% Training Set Error
h_p = [1 x_batch] * w;
h = act([1 h_p], act_func);
o_p = h * v;
o = act(o_p, act_func);

dist = norm(o - x_batch)



%yhat = act(act(train_images' * w, act_func) * v, act_func);
%error = norm(yhat - train_images')


